# (PART) Linear Regression {-}

```{r 12-setup, echo = FALSE}
knitr::opts_chunk$set(fig.align = "center", comment = '', warning = FALSE, message = FALSE, fig.height = 7, fig.width = 12, cache = TRUE)
```

# Scatter Plots and Correlation

## Scatter Plots

Everything we've done to this point has examined one variable of a data set, or things that could be represented by a single vector. While this helps us to understand that one particular variable, it's much more interesting to us to examine how variables relate to one another. One way to visualize how they relate is through a <span class = 'vocab'>**scatter plot**</span>. A scatter plot puts one variable -- an <span class = 'vocab'>**independent variable**</span>, or <span class = 'vocab'>**predictor**</span>, on the $x$-axis, and a second variable -- the <span class = 'vocab'>**response**</span>, or <span class = 'vocab'>**dependent variable**</span>, on the $y$-axis. Usually, we're trying to show how the independent variable explains the dependent variable.

Say, for example, we're trying to find a relationship between a student's midterm exam score and their final exam score. Let's have a small class of seven students, with midterm and final scores according to the following table.

```{r 12-scatterplot-example-table, echo = FALSE}
Midterm = c(55, 60, 70, 80, 85, 90, 100)
Final   = c(62, 50, 65, 70, 95, 80, 90)
test_scores = data.frame(Midterm, Final)
row.names(test_scores) = c('Student 1',
                          'Student 2',
                          'Student 3',
                          'Student 4',
                          'Student 5',
                          'Student 6',
                          'Student 7')
knitr::kable(test_scores,
             format = 'html',
             align = 'c',
             booktabs = TRUE) %>% kableExtra::kable_styling(full_width = FALSE)
```

It's kind of hard to tell the general trend of the data from just looking at the table, so let's plot the points. We'll make the $x$-axis the midterm scores and the $y$-axis as the final scores. <span class = 'note'>*Note: we have the midterm and final scores stored in a data frame called*</span> <span style = 'color: #a21bd7'>`test_scores`.</span>

<span class = 'tip'>*Pro tip: If you're ever not sure which variable goes where, think about which variable you'd try in predict. In this example, we're trying to predict a final score from a midterm score, so the final should go on the $y$-axis.*</span>

To make the scatter plot, we'll use the `plot` function (see `?plot` for more information) and make use of the <a href = 'percentiles-and-box-plots.html#formula-syntax'>forumla syntax</a> we discussed before. Now, however, we can write it as `Dependent variable ~ independent variable`.

```{r 12-scatterplot-example}
plot(Final ~ Midterm,
     data = test_scores,
     pch = 16, # Makes points into closed dots
     col = '#0088ce',
     xlab = 'Midterm',
     ylab = 'Final',
     main = 'Final vs. Midterm',
     cex.axis = 1.5, # Controls font size of axis numbers
     cex.main = 1.5, # Controls font size of title labels
     cex.lab  = 1.5, # Controls font size of axis label labels
     cex = 1.5 # Controls size of points
)
```

Now it's much easier to see! Typically, the better a student did on the midterm (further to the right on the $x$), the better they did on the final (higher up on the $y$-axis). We can conclude that an increase in midterm scores is then *associated* with an increased final score. This is called a <span class = 'vocab'>**positive association**</span>. If instead increasing $x$ meant *decreasing* $y$, we'd call this a <span class = 'vocab'>**negative association**</span>.

<a name = 'correlation'></a>

## Correlation

This is great, but it's kind of general to just talk about associations. How do we tell if an association is strong or not? This is where the idea of <span class = 'vocab'>**correlation**</span> comes in. Correlation measures how closely the points follow a line, and they can be summarized by the <span class = 'vocab'>**correlation coefficient, $r$**</span>. It does **not** measure points that are clustered around a curve. A good rule of thumb is that if the data is roughly football shaped, you can use $r$.

If the points fall perfectly on a line and are negatively associated, $r$ = -1. If the points fall perfectly on a line and are positively associated, $r$ = +1. If there's no association between the independent and dependent variables, the correlation is 0.

In other words, a correlation of $r = \pm$1 means that you can know *exactly* what $y$ is for any given $x$ value. Examples are converting units (i.e. temperature from Fahrenheit to Celsius or vice versa) or anything that's described by a line (i.e. the $x$ and $y$ values from the equation $y = 6x + 9$). Things that aren't related, such as weight of college freshmen and ACT scores or class attendance and number of pets you own, have a correlation coefficient of $r$ = 0.

```{r 12-correlation-plot-examples, echo = FALSE}
set.seed(696969696)
inches = seq(48, 76, by = 2)
cm     = 2.54 * inches
x = 1:100
y = 100 - x
random_x = 10 * rnorm(100)
random_y = 10 * rnorm(100)

par(mfrow = c(1, 2))
plot(
  inches,
  cm,
  pch = 16,
  col = '#e04e39',
  xlab = 'Inches',
  ylab = 'Centimeters',
  main = 'Correlation of +1'
)
abline(lm(cm ~ inches),
       col = '#13294b',
       lwd = 2,
       lty = 3)
points(x = inches,
       y = cm,
       col = '#e04e39',
       pch = 16)

plot(
  x,
  y,
  pch = 16,
  cex = .8,
  col = '#e04e39',
  xlab = 'Number',
  ylab = '100 - Number',
  main = 'Correlation of -1'
)
abline(lm(y ~ x),
       col = '#13294b',
       lwd = 1,
       lty = 3)
points(x = x,
       y = y,
       col = '#e04e39',
       pch = 16)

par(mfrow  = c(1, 1))
plot(
  random_x,
  random_y,
  pch = 16,
  col = '#e04e39',
  xlab = 'Independent Variable',
  ylab = 'Dependent Variable',
  main = 'Correlation of 0'
)
abline(h = 0,
       col = '#13294b',
       lwd = 2,
       lty = 3)
points(x = random_x,
       y = random_y,
       col = '#e04e39',
       pch = 16)
```

## Calculating $r$ and `cor()`

To calculate the correlation coefficient, just follow a simple 3-step process.

1) Convert both $x$ and $y$ to Z-scores

2) Multiply the Z-scores of $x$ and $y$ together

3) Take the average of the products you just found in step 2

Like <a href = 'measures-of-central-tendency.html#sd-by-hand'>calculating a standard deviation by hand</a>, it's easy to see (and do) the calculation of a $r$ in a table. Let's make a small data set of 4 students' scores on quiz 1 and quiz 2.

```{r 12-cor-by-hand, echo = FALSE}
quiz1 = c(10, 9, 5, 4)
quiz2 = c(10, 7, 9, 6)
zq1 = (quiz1 - mean(quiz1)) / stdv(quiz1)
zq2 = (quiz2 - mean(quiz2)) / stdv(quiz2)
prods = zq1 * zq2

cordf = data.frame(quiz1, quiz2, zq1, zq2, prods)
names(cordf) = c('Quiz 1', 'Quiz 2', 'Z$_\\text{Quiz 1}$', 'Z$_\\text{Quiz 2}$', 'Z$_\\text{Quiz 1} \\cdot$ Z$_\\text{Quiz 2}$')
row.names(cordf) = c('Student 1', 'Student 2', 'Student 3', 'Student 4')

knitr::kable(cordf, format = 'html', align = 'c', digits = 1)
```

Averaging the last column, Z$_\text{Quiz 1} \cdot$ Z$_\text{Quiz 2}$, we get that the correlation coefficient is `r round(mean(prods), 1)`.

Of course, `R` can calculate this for us. We can get $r$ through the `cor()` function, which just needs the two vectors for which you'd like to calculate the correlation.

```{r 12-cor-demo-code, eval = FALSE}
quiz1 = c(10, 9, 5, 4)
quiz2 = c(10, 7, 9, 6)
cor(quiz1, quiz2)
```

```{r 12-cor-demo-eval, echo = FALSE}
quiz1 = c(10, 9, 5, 4)
quiz2 = c(10, 7, 9, 6)
round(cor(quiz1, quiz2), 1)
```

## Statistics of the "Cloud" Scatter Plot

When our data is roughly football-shaped (like we see below), there are five statistics, called the <span class = 'vocab'>**summary statistics**</span>, that we'll want to pay attention to.

- The <span class = 'vocab'>**Avg$_x$**</span> is the average (mean) of the variable on the $x$-axis

- The <span class = 'vocab'>**Avg$_y$**</span> is the average of the variable on the $y$-axis

    - The point (Avg$_x$, Avg$_y$) is referred to as the <span class = 'vocab'>**point of averages**</span>

- The <span class = 'vocab'>**SD$_x$**</span> is the standard deviation of the variable on the $x$-axis

- The <span class = 'vocab'>**SD$_y$**</span> is the standard deviation of the variable on the $y$-axis

- The correlation coefficient, $r$, which describes how closely $x$ and $y$ follow a line

These statistics are usually given to you in class, but you'll have to calculate them yourself or have `R` calculate them on any data set in practice! We'll use the data from Survey 1 (loaded as `survey1`) as we did before, and focus on the `height` and `weight` variables, since these are probably correlated. We'll make use of the `stdv()` function we wrote <a href = 'measures-of-central-tendency.html#stdv-function'>before</a>.

```{r 12-summary-statistics-calculation}
(means = c(mean(survey1$height), mean(survey1$weight)))
(stdvs = c(stdv(survey1$height), stdv(survey1$weight)))
(cor = cor(survey1$height, survey1$weight))
```

<span class = 'tip'>*Pro tip: enclosing code in* `()` *while making an assignment both assigns the variable and displays the calculation*</span>

Reformatting this information into a table, we'd summarize it as

<div style = 'text-align: center'>Summary Statistics for `height` and `weight` from `survey1`</div>

```{r 12-summary-statistics-table, echo = FALSE}
cors = rep(paste('$r$ =', round(cor, 1)), 2)
summary_stats = data.frame(means, stdvs, cors)
names(summary_stats) = c('Average', 'Standard Deviation', '')
row.names(summary_stats) = c('`height`', '`weight`')
knitr::kable(summary_stats,
             format = 'html',
             align = 'c',
             digits = 1) %>% kableExtra::column_spec(4, bold = TRUE) %>% kableExtra::collapse_rows(columns = 4)
```

One last step before we start using this information: let's plot what this looks like so we can see what the data looks like. Let's let our $x$-axis be `height` and our $y$-axis be `weight`.

```{r 12-summary-statistics-plot}
plot(
  weight ~ height,
  data = survey1,
  pch = 16,
  xlab = 'Height in Inches',
  ylab = 'Weight in Pounds',
  main = 'Height vs. Weight',
  col = '#0088ce'
)
```

The data is shaped roughly like a football, so we can continue!

First, let's add in the point of averages that we talked about before. We'll make that point <span style = 'color: #939598'>grey</span>, and show the intersecting lines on the plot with <span style = 'color: #ffcc33>gold</span> and <span style = 'color: #7a0019'>maroon</span>.

```{r 12-summary-statistics-plot-point-of-averages, echo = FALSE}
plot(
  weight ~ height,
  data = survey1,
  pch = 16,
  xlab = 'Height in Inches',
  ylab = 'Weight in Pounds',
  main = 'Height vs. Weight',
  col = '#0088ce'
)
abline(h = mean(survey1$weight), col = '#ffcc33', lwd = 1.5, lty = 2)
abline(v = mean(survey1$height), col = '#7a0019', lwd = 1.5, lty = 2)
points(x = mean(survey1$height), y = mean(survey1$weight), col = '#939598', pch = 16)
```

<a name = 'sd-line'></a>

## The SD Line

The <span class = 'vocab'>**SD line**</span> is the line that goes through the tips of the football, passing through the point of averages. Its slope is defined by

$$
\text{Slope of SD Line} = \begin{cases}
  \frac{\text{SD}_\text{y}}{\text{SD}_\text{x}} & r > 0 \\
  -\frac{\text{SD}_\text{y}}{\text{SD}_\text{x}} & r < 0
\end{cases}
$$

In our example, the slope of the SD line is thus $\frac{`r round(stdvs[2], 1)`}{`r round(stdvs[1], 1)`} =$ `r round(round(stdvs[2], 1)/round(stdvs[1], 1), 1)`. We can add this line to our plot with `abline()` function. `abline()` looks for arguments `a` (the intercept of the line) and `b` (the slope of the line). We've got the slope, but we just need to find the intercept.

Some quick algebra gives us the following, assuming we know the slope, average in $x$, and average in $y$.

<div style = 'text-align: center'>

y = slope $\cdot$ x + intercept

</div>

Plugging in the fact that the SD line *has* to go through the point of averages (i.e. the point (Avg$_\text{x}$, Avg$_\text{y}$) has to satisfy the equation we're looking for), we can plug in (Avg$_\text{x}$, Avg$_\text{y}$) for x and y respectively.

<div style = 'text-align: center'>

Avg$_\text{y}$ = slope $\cdot$ Avg$_\text{x}$ + intercept

Avg$_\text{y}$ - slope $\cdot$ Avg$_\text{x}$ = intercept

</div>

In our case, this gives that `r round(mean(survey1$weight), 1)` - (`r round(round(stdvs[2], 1)/round(stdvs[1], 1), 1)` $\cdot$ `r round(mean(survey1$weight, 1))`) = **`r round(round(mean(survey1$weight), 1) - ((round(stdvs[2], 1)/round(stdvs[1], 2)) * round(mean(survey1$height, 1))), 1)`**. So adding the following line to our plot

```{r 12-add-abline-code-display, eval = FALSE}
abline(a = -404.9, b = 8.2)
```

will add the SD line to our plot.

```{r 12-actually-add-abline, echo = FALSE}
plot(
  weight ~ height,
  data = survey1,
  pch = 16,
  xlab = 'Height in Inches',
  ylab = 'Weight in Pounds',
  main = 'Height vs. Weight',
  col = '#0088ce'
)

abline(
  h = mean(survey1$weight),
  col = '#ffcc33',
  lwd = 1.5,
  lty = 2
)

abline(
  v = mean(survey1$height),
  col = '#7a0019',
  lwd = 1.5,
  lty = 2
)

sd_line_slope = stdvs[2] / stdvs[1]

abline(a = means[2] - (sd_line_slope * means[1]),
       b = sd_line_slope,
       col = '#000000',
       lwd = 1.5,
       lty = 2)

points(
  x = mean(survey1$height),
  y = mean(survey1$weight),
  col = '#939598',
  pch = 16
)
```

## Subsetting and Ecological Correlations

### Subsetting {-}
Sometimes, we may think that it's useful to summarize data into groups, then talk about the statistics of that group. For example, we may want to compare how different ethnicities in class scored on their midterms. In this case, we don't necessarily care about how well each student did, but we're interested in how groups of them did. This is easy to see with [this data](data/Combined Fall 2017 Survey 4.csv) from Bonus Survey 4. We'll import it as `survey4`, and you can find the description of the dataset [here](http://courses.las.illinois.edu/stat/stat100/survey/archive/Stat100_200_2017fall_survey04.html).

```{r 12-load-survey-4}
survey4 = read.csv('data/Combined Fall 2017 Survey 4.csv')
```

The `ethnicity` variable is the one that we'd like to group our data by. `ethnicity` in this data set can be any one of the following:

- Black

- East Asian

- Hispanic

- South Asian

- White

- Other

We have a few options of how to group, or <span class = 'vocab'>**subset**</span>, the data, some of which are more memory-intensive than others. Method one is to use the `subset()` function. If, for example, we wanted to only look at East Asian students' performance on exam 1, we could write something like

```{r 12-subset-function-example}
east_asian = subset(survey4, survey4$ethnicity == 'East Asian')
mean(east_asian$Exam1)
```

<span class = 'note'>*Note: We used a double equals (*</span><span style = 'color: #a21bd7'> `==` </span><span class = 'note'>*) to evaluate the condition, and we passed the condition we were looking for as a string.*

This takes all of the data from `survey4`, finds which rows have `ethnicity` of `'East Asian'` (again, matching case), and puts them into their own data frame called `east_asian`. One great perk of this method is that it's very easy to keep track of things, since you can then call on parts of the new, subsetted data frame just like you would have on the bigger data frame. Even the names of the features stay the same. However, this method can get fairly memory-intensive since it takes memory to store the data frame we created. The more subsets you'd like to have, the more memory you start to use up, and the slower your code may run.

Method 2 is to take advantage of <a href = 'operators.html#vectorization'>vectorization</a> again. We can subset the data here by using `[]`, `$`, and even do calculations, all in one step. Let's try to get the same result as above, but this time we use vectorization.

```{r 12-subset-vectorization-example}
mean(survey4$Exam1[survey4$ethnicity == 'East Asian'])
```

If this is confusing, start from the inside and work your way out. First, we found the rows where `ethnicity` was `'East Asian'`. Then, from these row numbers (indexes), we took the `exam1` numbers, and lastly took the mean of them. As you can see, they produce the same result, but this one uses less memory and less lines of code. Pretty cool!

The last point we should make about subsetting is that using `[]` is equivalent to `subset()`. If we wanted to make the same subset using `[]`, we could do something like this. Just so we don't overwrite `east_asian`, we'll call this one `e_a`, and use the `identical()` function to check if they're the same.

```{r 12-subset-bracket-proof}
east_asian = subset(survey4, survey4$ethnicity == 'East Asian')
e_a = survey4[survey4$ethnicity == 'East Asian', ]
identical(east_asian, e_a)
```

<span class = 'note'>*Note: in creating*</span><span style = 'color: #a21bd7'> `e_a` </span><span class = 'note'>*, we had to include the*</span><span style = 'color: #a21bd7'> `,` </span><span class = 'note'>*so that we could get all rows. If you wanted only certain columns, you could put something after the*</span><span style = 'color: #a21bd7'> `,` </span><span class = 'note'> *to get only those columns.*</span>

### Ecological Correrlations {-}

Now that we know how to restrict data by conditions, we can go back to our original question of representing a bunch of data by the groups they belong to. If we wanted to visualize the original data by ethnicity, one option we have is to color the points accordingly. Remember, we're interested in the relationship between scores on exams 1 and 2. If we treat each student as a unique data point, the data has correlation `r round(cor(survey4$Exam1, survey4$Exam2), 1)`

```{r 12-set-temp-palette, echo = FALSE}
palette(c('#023f57', '#067b97', '#c7d6a0', '#571d02', '#973106', '#d6a0c7'))
```

```{r 12-plot-color-by-factor-code}
plot(Exam2 ~ Exam1, data = survey4,
     xlab = 'Exam 1 Score',
     ylab = 'Exam 2 Score',
     main = 'Exam 1 and 2 Scores for All Students',
     col = survey4$ethnicity,
     pch = 16,
     cex = .8
)
legend(x = 60, y = 35,
       legend = unique(survey4$ethnicity),
       col = unique(survey4$ethnicity),
       pch = 16
)
```

Another option we have, however, is to condense the plot to be the averages of each ethnicity for each exam.

```{r 12-get-means}
exam_1_means = c(mean(survey4$Exam1[survey4$ethnicity == 'Black']),
                 mean(survey4$Exam1[survey4$ethnicity == 'East Asian']),
                 mean(survey4$Exam1[survey4$ethnicity == 'Hispanic']),
                 mean(survey4$Exam1[survey4$ethnicity == 'South Asian']),
                 mean(survey4$Exam1[survey4$ethnicity == 'White']),
                 mean(survey4$Exam1[survey4$ethnicity == 'Other']))

exam_2_means = c(mean(survey4$Exam2[survey4$ethnicity == 'Black']),
                 mean(survey4$Exam2[survey4$ethnicity == 'East Asian']),
                 mean(survey4$Exam2[survey4$ethnicity == 'Hispanic']),
                 mean(survey4$Exam2[survey4$ethnicity == 'South Asian']),
                 mean(survey4$Exam2[survey4$ethnicity == 'White']),
                 mean(survey4$Exam2[survey4$ethnicity == 'Other']))
```

```{r 12-ecological-correlation-plot, echo = FALSE}
plot(
  exam_1_means,
  exam_2_means,
  xlab = 'Exam 1 Score',
  ylab = 'Exam 2 Score',
  main = 'Exam 1 and 2 Scores by Ethnicity',
  col = c('#023f57', '#067b97', '#c7d6a0', '#571d02', '#973106', '#d6a0c7'),
  pch = 16
)
legend(
  82,
  86,
  legend = c(
    'White',
    'Hispanic',
    'East Asian',
    'South Asian',
    'Other',
    'Black'
  ),
  col = c(
    '#d6a0c7',
    '#973106',
    '#571d02',
    '#c7d6a0',
    '#067b97',
    '#023f57'
  ),
  pch = 16
)
```

These have a higher correlation ($r$ = `r round(cor(exam_1_means, exam_2_means), 1)`) and visually look like they follow a line much closer. This makes sense: it takes two points to determine a line. The more points we have, the less they'll fall on a line unless we know that they were generated by some rule or equation that directly ties them together. In subsetting our data, we went from `r nrow(survey4)` data points to only 6. It's much easier for 6 data points to fall on a line than it is for `r nrow(survey4)`. This is the effect of an <span class = 'vocab'>**ecological correlation**</span>.

Higher correlation may seem better, but that's not always true. By reducing each student to their ethnicity, we have lost a lot of data points from our data set (`r nrow(survey4) - 6` to be exact). This makes it easy to talk about ethnicities, but we may lose the understanding of the performance of an individual in the class.

## Summary of Correlation

Some facts about $r$ to keep in mind:

1) **Correlation *is not* causation**

2) $r$ is unitless, since when switching to Z-scores, the data loses its units

3) $r$ does *not* change by doing any of the following:

    - Adding/subtracting the same number from *all* values of $x$ and/or $y$
    - Multiplying *all* values of $x$ and/or $y$ by the same number. <span class = 'note'>*Note: multiplying either $x$ or $y$ (but not both) by a negative number changes the sign of*</span> <span style = 'color: #a21bd7'>$r$</span>
    - Changing units of the original data (see fact 2)
    - Switching all of the $x$ values with all of the $y$ values
    
If you don't believe any of these facts, go ahead and prove them to yourself, or come in to office hours and ask a TA to help you!